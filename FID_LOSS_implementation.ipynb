{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPw91MIKhkai5Vh0at4cLEq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stanfording/Trying-FID-LOSS/blob/main/FID_LOSS_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Goal:   Testing if FID Loss works on training GAN\n",
        "\n"
      ],
      "metadata": {
        "id": "7gaYl2YwkRiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the preprocessed celebHD data from google drive"
      ],
      "metadata": {
        "id": "piBy5s1LBUw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #Download the dataset\n",
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1KqBRLsB0CJuQGycvaPINwaPgcGDUsAxN' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1KqBRLsB0CJuQGycvaPINwaPgcGDUsAxN\" -O \"proCeleba.zip\" && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# #unzip the dataset\n",
        "# !unzip \"/content/proCeleba.zip\"\n",
        "\n",
        "# #remove unnecessary files\n",
        "# !rm -rf /content/__MACOSX"
      ],
      "metadata": {
        "id": "Zp1iaK-uBRrV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "03mgtLjDBfOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "from torch.autograd import Variable, grad\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io\n",
        "import copy"
      ],
      "metadata": {
        "id": "s_TyTXFBBhS1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set initial hyperparameters"
      ],
      "metadata": {
        "id": "QwBlsx3WBmOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "resolution = 16\n",
        "\n",
        "img_fold_dir_64_reso = f\"/content/proCeleba/{resolution}\"\n",
        "\n",
        "iteration = 200\n",
        "\n",
        "critic = 5          \n",
        "\n",
        "eval_size = 25\n",
        "\n",
        "laten_space = 100\n",
        "\n",
        "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
        "\n",
        "log_folder = \"log\"\n",
        "!mkdir \"log\"\n",
        "!mkdir \"log/checkpoint\"\n",
        "!mkdir \"log/sample\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk8t27hRBnqr",
        "outputId": "74670a5d-8198-4889-ae29-cb3b521385f7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘log’: File exists\n",
            "mkdir: cannot create directory ‘log/checkpoint’: File exists\n",
            "mkdir: cannot create directory ‘log/sample’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show me which gpu I am using."
      ],
      "metadata": {
        "id": "mPrOMKEbBylH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi64DRdjBzd4",
        "outputId": "c4edc98e-c000-465b-9972-f885493ec31e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-07454f12-3b42-7271-d801-ce798afb5a0f)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre loading the data"
      ],
      "metadata": {
        "id": "koic4if7B1MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a data class for load unclassfied data.\n",
        "class Get_No_Classes_Img_Dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, folder_dir, transform = None):\n",
        "        self.folder_dir = os.path.join(folder_dir)\n",
        "        self.transform = transform\n",
        "        self.image_list = os.listdir(self.folder_dir)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.folder_dir))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        image_name = self.image_list[index]\n",
        "        \n",
        "        image_dir = os.path.join(self.folder_dir, image_name)\n",
        "        \n",
        "        image = io.imread(image_dir)\n",
        "        \n",
        "        if (self.transform != None):\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image\n",
        "    \n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()       #From Batch * Highth * Width * Channel to Batch * Channel * Highth * Width\n",
        "                                  #Which is what pytorch CNN can work with.\n",
        "]) \n",
        "\n",
        "dataset = Get_No_Classes_Img_Dataset(img_fold_dir_64_reso, transform = transform) \n",
        "                                                            # datasets[0].shape = (16,16,3)\n",
        "                                                            # len(datasets) = 28000\n",
        "total_data_len = len(dataset)\n",
        "                                                                                            \n",
        "#datasets_batched = DataLoader(datasets, batch_size = batch_size) #loader is renewed every epoch\n"
      ],
      "metadata": {
        "id": "Vt4rxDBeB6fo"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "loader = iter(loader)\n",
        "print(next(loader).shape) \n",
        "```\n",
        "will output\n",
        "\n",
        "\n",
        "```\n",
        "torch.Size([batch_size, 3, resolution, resolution])\n",
        "```\n",
        "\n",
        "So data loading is ready.\n",
        "\n",
        "What's left is keep using \n",
        "\n",
        "```\n",
        "next(loader)\n",
        "```\n",
        "to access each batch of data\n"
      ],
      "metadata": {
        "id": "J8EFVPstlDHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize a picture"
      ],
      "metadata": {
        "id": "J2dOjqrRCYOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Viewing one data sample function:\n",
        "def showOneImge(img, i, shouldSave):\n",
        "    \n",
        "    img = img.squeeze()\n",
        "    \n",
        "    img = transforms.ToPILImage()(img)\n",
        "    \n",
        "    plt.figure(figsize = (10,10), dpi = 10)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    if shouldSave:\n",
        "      saveDir = f'{log_folder}/sample/{str(i).zfill(6)}.png'\n",
        "      plt.imshow(img)\n",
        "      plt.savefig(saveDir, bbox_inches='tight', pad_inches = 0)\n",
        "      img = Image(saveDir)\n",
        "      display(img)\n",
        "    else:\n",
        "      deleteDir = f\"{log_folder}/sample/Delete.png\"\n",
        "      plt.imshow(img)\n",
        "      plt.savefig(deleteDir, bbox_inches='tight', pad_inches = 0)\n",
        "      img = Image(deleteDir)\n",
        "      display(img)\n",
        "      !rm \"/content/log/sample/Delete.png\"\n",
        "    return \n",
        "\n",
        "''' Testing showOneImage'''\n",
        "# loader = DataLoader(datasets, batch_size = batch_size)\n",
        "\n",
        "# data = iter(loader)\n",
        "\n",
        "# oneSample = next(data)[0]\n",
        "\n",
        "# showOneImge(oneSample, 9999, True)\n",
        "\n",
        "\n",
        "def showMoreImages(img, num):\n",
        "\n",
        "  subplot_x = int(num ** (1/2))\n",
        "  subplot_y = num // subplot_x\n",
        "  plt.figure(figsize = (2,2))\n",
        "  for i in range(len(img)):\n",
        "      aimg = transforms.ToPILImage()(img[i])\n",
        "      plt.subplot(subplot_x, subplot_y, i+1)\n",
        "      plt.imshow(aimg)\n",
        "      plt.axis('off')\n"
      ],
      "metadata": {
        "id": "EjQccnhTCZgU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------\n",
        "\n",
        "### Now Designing the simple GAN network"
      ],
      "metadata": {
        "id": "xf_Ocw2onofc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Define the generator\n",
        "\"\"\"\n",
        "\n",
        "class G(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.laten = nn.Sequential(\n",
        "            nn.Linear(laten_space, 100),\n",
        "            nn.Linear(100, 500),\n",
        "            nn.Linear(500, 128 * resolution * resolution))\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, (3, 3), padding = \"same\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 32, (3, 3), padding = \"same\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout2d(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 3, (3, 3), padding = \"same\"),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, theInput, batch_size):\n",
        "        \n",
        "        x = self.laten(theInput)\n",
        "        \n",
        "        x = t.reshape(x, (batch_size, 128, resolution, resolution))\n",
        "         \n",
        "        x = self.model(x)\n",
        "            \n",
        "            \n",
        "        return x\n",
        "    \n",
        "class D(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.netWork = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, (3, 3), padding = \"same\"),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout2d(0.3),\n",
        "            nn.Conv2d(64, 128, (3, 3), stride = (3, 3)),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv2d(128, 1, (3, 3), stride = (3, 3)),\n",
        "            nn.Flatten())\n",
        "        \n",
        "    def forward(self, theInput):\n",
        "        \n",
        "        return self.netWork(theInput)"
      ],
      "metadata": {
        "id": "lhZEIrxxCjhv"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the network"
      ],
      "metadata": {
        "id": "VVyrduFTClyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Testing the net work:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# oneImg = next(iter(datasets))[0]\n",
        "\n",
        "# showOneImge(oneImg, 0)\n",
        "\n",
        "# oneImg = oneImg.expand(1,3,64,64)\n",
        "\n",
        "# print(oneImg.shape)\n",
        "\n",
        "# print(oneImg)\n",
        "\n",
        "# #img into G to test shape\n",
        "\n",
        "# input_noise_example = t.randn((batch_size, 1, 1, 5))\n",
        "\n",
        "# a = G()(input_noise_example, batch_size)\n",
        "# print(a[0])\n",
        "# showOneImge(a[0], 0)\n",
        "\n",
        "# b = D()(next(loader))\n",
        "\n",
        "# print(b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VnPyQQNbCpB0",
        "outputId": "c4b3ba41-2e27-46e4-d1d3-c68082c725d6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nTesting the net work:\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Penalty from wGAN."
      ],
      "metadata": {
        "id": "LiBvvKgwCrnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_penalty(D, real_samples, fake_samples, current_batch_size):\n",
        "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    # Random weight term for interpolation between real and fake samples\n",
        "    alpha = t.randn((current_batch_size, 1, 1, 1)).to(device)\n",
        "    # Get random interpolation between real and fake samples\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
        "    \n",
        "    \n",
        "    d_interpolates = D(interpolates)\n",
        "    \n",
        "    \n",
        "    grad_x_hat = grad(\n",
        "            outputs=d_interpolates.sum(), inputs=interpolates, create_graph=True)[0]\n",
        "    grad_penalty = ((grad_x_hat.view(grad_x_hat.size(0), -1)\n",
        "                      .norm(2, dim=1) - 1)**2).mean()\n",
        "    grad_penalty = 10 * grad_penalty\n",
        "    \n",
        "    return grad_penalty"
      ],
      "metadata": {
        "id": "HpT5gBx3CyAC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try FID LOSS"
      ],
      "metadata": {
        "id": "4STG2MN5C4j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "from torchvision.models.feature_extraction import get_graph_node_names\n",
        "from torch.autograd import Function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import scipy.linalg as linalg\n",
        "\n",
        "\"\"\"MatrixSquareRoot is from https://github.com/steveli/pytorch-sqrtm/blob/master/sqrtm.py\"\"\"\n",
        "\n",
        "class MatrixSquareRoot(Function):\n",
        "    \"\"\"Square root of a positive definite matrix.\n",
        "    NOTE: matrix square root is not differentiable for matrices with\n",
        "          zero eigenvalues.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        m = input.detach().cpu().numpy().astype(np.float_)\n",
        "        sqrtm = t.from_numpy(linalg.sqrtm(m).real).to(input)\n",
        "        ctx.save_for_backward(sqrtm)\n",
        "        return sqrtm\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_input = None\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            sqrtm, = ctx.saved_tensors\n",
        "            sqrtm = sqrtm.data.cpu().numpy().astype(np.float_)\n",
        "            gm = grad_output.data.cpu().numpy().astype(np.float_)\n",
        "\n",
        "            # Given a positive semi-definite matrix X,\n",
        "            # since X = X^{1/2}X^{1/2}, we can compute the gradient of the\n",
        "            # matrix square root dX^{1/2} by solving the Sylvester equation:\n",
        "            # dX = (d(X^{1/2})X^{1/2} + X^{1/2}(dX^{1/2}).\n",
        "            grad_sqrtm = linalg.solve_sylvester(sqrtm, sqrtm, gm)\n",
        "\n",
        "            grad_input = t.from_numpy(grad_sqrtm).to(grad_output)\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "sqrtm = MatrixSquareRoot.apply\n",
        "\n",
        "\"\"\" FID is modified from official pytorch implementation \"\"\"\n",
        "\n",
        "class FID_Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.model = t.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
        "    \n",
        "      self.model.eval()\n",
        "    \n",
        "      self.model = create_feature_extractor(self.model, {'avgpool': 'feat'})\n",
        "\n",
        "\n",
        "    def cov(self, tensor, rowvar=True, bias=False):\n",
        "      \"\"\"Estimate a covariance matrix (np.cov)\n",
        "      https://gist.github.com/ModarTensai/5ab449acba9df1a26c12060240773110\n",
        "      \"\"\"\n",
        "      tensor = tensor if rowvar else tensor.transpose(-1, -2)\n",
        "      tensor = tensor - tensor.mean(dim=-1, keepdim=True)\n",
        "      factor = 1 / (tensor.shape[-1] - int(not bool(bias)))\n",
        "      return factor * tensor @ tensor.transpose(-1, -2).conj()\n",
        "\n",
        "\n",
        "    def sqrtm(self, a):\n",
        "      # Computing diagonalization\n",
        "          evalues, evectors = t.linalg.eigh(a)\n",
        "          # Ensuring square root matrix exists\n",
        "          #assert (evalues >= 0).all()\n",
        "          covmean = evectors @ t.diag(t.sqrt(evalues)) @ t.linalg.inv(evectors)\n",
        "          return covmean\n",
        "\n",
        "  # calculate frechet inception distance\n",
        "  # A faster FID calculation modified from https://github.com/mseitzer/pytorch-fid/blob/master/src/pytorch_fid/fid_score.py\n",
        "    def calculate_frechet_distance(self, ac1, ac2, eps=1e-6):\n",
        "        \"\"\"Numpy implementation of the Frechet Distance.\n",
        "        The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
        "        and X_2 ~ N(mu_2, C_2) is\n",
        "                d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
        "        Stable version by Dougal J. Sutherland.\n",
        "        Params:\n",
        "        -- mu1   : Numpy array containing the activations of a layer of the\n",
        "                  inception net (like returned by the function 'get_predictions')\n",
        "                  for generated samples.\n",
        "        -- mu2   : The sample mean over activations, precalculated on an\n",
        "                  representative data set.\n",
        "        -- sigma1: The covariance matrix over activations for generated samples.\n",
        "        -- sigma2: The covariance matrix over activations, precalculated on an\n",
        "                  representative data set.\n",
        "        Returns:\n",
        "        --   : The Frechet Distance.\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        mu1 = t.mean(ac1)\n",
        "        sigma1 = self.cov(ac1)\n",
        "        \n",
        "        mu2 = t.mean(ac2)\n",
        "        sigma2 = self.cov(ac2)\n",
        "        \n",
        "        mu1 = t.atleast_1d(mu1)\n",
        "        mu2 = t.atleast_1d(mu2)\n",
        "        \n",
        "        sigma1 = t.atleast_2d(sigma1)\n",
        "        sigma2 = t.atleast_2d(sigma2)\n",
        "        \n",
        "        assert mu1.shape == mu2.shape, \\\n",
        "            'Training and test mean vectors have different lengths'\n",
        "        assert sigma1.shape == sigma2.shape, \\\n",
        "            'Training and test covariances have different dimensions'\n",
        "        \n",
        "        diff = mu1 - mu2\n",
        "        \n",
        "        # Product might be almost singular\n",
        "        #print(\"sigma1 shape: \", sigma1.shape)\n",
        "        #print(\"sigma2 shape: \", sigma2.shape)\n",
        "        \n",
        "        \n",
        "        # Computing diagonalization\n",
        "        #covmean = self.sqrtm(sigma1.T@sigma2)\n",
        "        covmean = sqrtm(sigma1@sigma2.T)\n",
        "        #print(covmean.shape)\n",
        "        if not t.isfinite(covmean).all():\n",
        "            msg = ('fid calculation produces singular product; '\n",
        "                  'adding %s to diagonal of cov estimates') % eps\n",
        "            #print(msg)\n",
        "            offset = t.eye(sigma1.shape[0]) * eps\n",
        "            covmean = sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "        \n",
        "        #Numerical error might give slight imaginary component\n",
        "        if t.is_complex(covmean):\n",
        "            if not t.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "                m = t.max(np.abs(covmean.imag))\n",
        "                raise ValueError('Imaginary component {}'.format(m))\n",
        "            covmean = covmean.real\n",
        "        \n",
        "        tr_covmean = t.trace(covmean)\n",
        "        \n",
        "        return  (diff.dot(diff) + t.trace(sigma1) + t.trace(sigma2) - 2 * tr_covmean)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, fake, real):\n",
        "      \n",
        "        upsamle_layer = t.nn.UpsamplingBilinear2d(size=299)\n",
        "    \n",
        "        transform = transforms.Compose([\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    \n",
        "        fake = upsamle_layer(fake)\n",
        "        fake = transform(fake)\n",
        "    \n",
        "        fake_feature = self.model(fake)['feat']\n",
        "        fake_feature = fake_feature.reshape((fake_feature.shape[0], 2048))\n",
        "    \n",
        "        real = upsamle_layer(real)\n",
        "        real = transform(real)\n",
        "    \n",
        "        real_feature = self.model(real)['feat']\n",
        "        real_feature = real_feature.reshape((real_feature.shape[0], 2048))\n",
        "        #print(\"real_feature: \", real_feature.shape)\n",
        "        FID_score = self.calculate_frechet_distance(real_feature, fake_feature)\n",
        "    \n",
        "        return FID_score\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Run1jf4C6QM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"Testing FID Loss\"\n",
        "# fake = t.randn((64, 3, 16, 16)).to(device)\n",
        "# real = t.randn((64, 3, 16, 16)).to(device)\n",
        "\n",
        "# #same = FID_loss(fake, fake)\n",
        "\n",
        "# dif = FID_loss(fake, real)\n",
        "\n",
        "# dif = dif.reshape((1,1))\n",
        "\n",
        "# dif = t.asarray(dif)\n",
        "\n",
        "# a = nn.Sequential(\n",
        "#     nn.Linear(1, 10),\n",
        "#     nn.Linear(10, 1)\n",
        "# )\n",
        "\n",
        "# a_opt = t.optim.Adam(a.parameters(), lr = 0.001)\n",
        "\n",
        "# loss = a(dif.float())\n",
        "\n",
        "# loss.backward()\n",
        "\n",
        "# print(a.state_dict())\n",
        "\n",
        "\n",
        "# #print(\"same: \", same)\n",
        "# print(\"dif\", dif)\n"
      ],
      "metadata": {
        "id": "Fw0SL-95z554"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the generator, discriminator, optimizer, labels, and loss."
      ],
      "metadata": {
        "id": "V0RdF6DhC8pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = G().to(device)\n",
        "discriminator = D().to(device)\n",
        "FID_loss = FID_Loss().to(device)\n",
        "\n",
        "G_optimizer = t.optim.Adam(generator.parameters(), lr = 0.00001)\n",
        "D_optimizer = t.optim.Adam(discriminator.parameters(), lr = 0.00001)\n",
        "\n",
        "label_real = t.ones((batch_size, 1)).to(device)\n",
        "label_fake = t.zeros((batch_size, 1)).to(device)"
      ],
      "metadata": {
        "id": "rpHbmg47DI1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ea617c-4e71-4282-c82f-8097ffb58222"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/feature_extraction.py:175: UserWarning: NOTE: The nodes obtained by tracing the model in eval mode are a subsequence of those obtained in train mode. When choosing nodes for feature extraction, you may need to specify output nodes for train and eval mode separately.\n",
            "  warnings.warn(msg + suggestion_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train decider"
      ],
      "metadata": {
        "id": "omNWHyD1DKxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(iteration):\n",
        "\n",
        "    p = tqdm(range(total_data_len // batch_size + 1)) # This is a progress bar run on each epoch\n",
        "    \n",
        "    datasets_batched = DataLoader(dataset, batch_size = batch_size)\n",
        "    \n",
        "    loader = iter(datasets_batched)\n",
        "\n",
        "    for j in p:\n",
        "        \n",
        "\n",
        "        batchNum = str(i+1)\n",
        "        \n",
        "        #Training the D\n",
        "        #real data\n",
        "        real = next(loader).to(device)\n",
        "\n",
        "        #current_batch size (the last batch is different than others)\n",
        "        current_batch_size, c, h, w = real.shape\n",
        "        #labels\n",
        "        label_real = 0.1 * t.randint(7,10,(current_batch_size,1)).type(t.half)\n",
        "        label_fake = 0.1 * t.randint(0,3,(current_batch_size,1)).type(t.half)\n",
        "        \n",
        "        input_noise = t.normal(0, 1, size = (current_batch_size, 1, 1, laten_space)).to(device)\n",
        "        fake = generator(input_noise, current_batch_size)\n",
        "        \n",
        "        total_loss = FID_loss(real, fake)\n",
        "\n",
        "        generator.zero_grad()\n",
        "        FID_loss.zero_grad()\n",
        "        total_loss.backward()\n",
        "        G_optimizer.step()\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "        \n",
        "        mse = \"Epoch: \" + batchNum\n",
        "        \n",
        "        p.set_description(mse)\n",
        "            \n",
        "        p.set_postfix(FID_loss = total_loss)\n",
        "        \n",
        "    if i == 0:\n",
        "        showOneImge(real[0], 99999, True)   \n",
        "    \n",
        "    if i % 2 == 0:\n",
        "      \n",
        "      showOneImge(real[0], 99999, False)\n",
        "      showOneImge(fake[0], i, False)\n",
        "      print(\"epoch = \", i + 1)  \n",
        "      #print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'.format(i, iteration, j+1, total_data_len // batch_size + 1, total_loss.item(), g_fake_loss.item(), real_score.mean().item(), fake_score.mean().item()))      \n",
        "      \n",
        "\n",
        "    if i % 50 == 0:\n",
        "      t.save(generator.state_dict(), f'{log_folder}/checkpoint/{str(i + 1).zfill(6)}_g.model')\n",
        "      t.save(discriminator.state_dict(), f'{log_folder}/checkpoint/{str(i + 1).zfill(6)}_d.model')\n"
      ],
      "metadata": {
        "id": "XoEqNnN3DLn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show Result"
      ],
      "metadata": {
        "id": "XHL0KU8LDknJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Generated\n",
        "generator.eval()\n",
        "\n",
        "with t.no_grad():\n",
        "  input_noise = t.normal(0, 1, size = (eval_size, 1, 1, laten_space)).to(device)\n",
        "  generated = generator(input_noise, eval_size)\n",
        "  showMoreImages(generated, eval_size)\n",
        "\n",
        "#Real\n",
        "datasets_batched = DataLoader(dataset, batch_size = eval_size)\n",
        "loader = iter(datasets_batched)\n",
        "real = next(loader)\n",
        "showMoreImages(real, eval_size)"
      ],
      "metadata": {
        "id": "xHULWTlKDnNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### remove log file when necessarry"
      ],
      "metadata": {
        "id": "vL3VVCKpDqr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/log/checkpoint\n",
        "\n",
        "# !mkdir /content/log/checkpoint\n",
        "\n",
        "# !rm -rf /content/log/sample\n",
        "# !mkdir /content/log/sample\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('/content/log') "
      ],
      "metadata": {
        "id": "qlMCFi_IDtmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}